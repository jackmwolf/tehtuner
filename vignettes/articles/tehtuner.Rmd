---
title: "Fitting Tuned Virtual Twins Models with tehtuner"
bibliography: '`r system.file("REFERENCES.bib", package="tehtuner")`'
output:
  html_document:
    df_print: paged
---

```{r include = FALSE}
set.seed(8675309)
library(tehtuner)
```

# Introduction

`tehtuner` is an R package that fits Virtual Twins models [@foster_subgroup_2011] to estimate the conditional average treatment effect (CATE) with controlled behavior when the CATE is uniform across the study population. To control the type-I error rate when testing treatment effect heterogeneity.

Data are assumed to be of the format $\{Y_i, A_i, \boldsymbol{X}_i\}_{i=1}^n$ where $Y_i$ is a continuous endpoint of interest, $A_i$ is a binary treatment indicator where $A_i=1$ indicates that subject $i$ was treated, and $\boldsymbol{X}_i$ is a vector of covariate measurements. It is assumed that $$\operatorname{E}(Y_i|A_i, \boldsymbol{X}_i) = h(\boldsymbol{X}_i) + A_ig(\boldsymbol{X}_i) $$ where $h(\boldsymbol{X}_i)$ gives the expected outcome under the control arm and $g(\boldsymbol{X}_i)$ is the CATE (because $\operatorname{E}(Y|A=1, \boldsymbol{X}) - \operatorname{E}(Y|A=0, \boldsymbol{X}) = g(\boldsymbol{X})$.) If $g(\boldsymbol{X}_i) = g(\boldsymbol{X}_j)$ for all $i, j$ there is no treatment effect heterogeneity and estimates for the CATE should not vary from subject-to-subject.

`tehtuner` estimates the CATE while controlling the probability of falsely estimating a heterogeneous treatment effect when all subjects share the same treatment effect: $$\Pr\left\{\hat{g}(\boldsymbol{X}_i)=\hat{g}(\boldsymbol{X}_j)|g(\boldsymbol{X}_i) =  \hat{g}(\boldsymbol{X}_j) \quad \forall i,j \right\} = 1 - \alpha$$ resulting in a type-I error rate of $\alpha$ when assessing if there is treatment effect heterogeneity by implementing the permutation procedure introduced in @wolf_permutation_2022. Briefly, the procedure considers the null distribution of the minimum null penalty parameter (MNPP) which is smallest possible penalty parameter that yield a model that is constant for all subjects and uses the $1-\alpha$ quantile of the null distribution as the penalty parameter when fitting the model to the observed data.

Tuned Virtual Twins models can be fit via the `tunevt` function after specifying estimation functions, the desired type-I error rate, and the number of permutations to perform to estimate the penalty parameter's null distribution:

```{r eval = FALSE}
tunevt(
  data,
  step1 = "randomforest",
  step2 = "rtree",
  alpha0 = 0.05,
  p_reps = 100
)
```

Estimation of the Virtual Twins model requires the user to fit two separate models. In Step 1 a model is fit for the conditional response in each arm of the study and in Step 2 the difference of these estimates is estimated as a simple function of the covariates. We will first provide an overview of supported methods in Step 1 and 2 and then implement the method to analyze data from a simulated clinical trial.

## Virtual Twins Step 1

Models $\hat{f}_1(\boldsymbol{X})$ and $\hat{f}_0(\boldsymbol{X})$ are fit to estimate $\operatorname{E}\left(Y_i|A_i=1, \boldsymbol{X}\right)$ and $\operatorname{E}\left(Y_i|A_i=0, \boldsymbol{X}\right)$, respectively. The difference of these estimates is used to estimate each subject's individual treatment effect: $\hat{Z}_i=\hat{f}_1(\boldsymbol{X}_i)-\hat{f}_0(\boldsymbol{X})$. Model forms should match the anticipated features of the data if possible; otherwise flexible data-adaptive methods are recommended [@deng_practical_2023].

Supported methods include linear models fit via the LASSO [@tibshirani_regression_1996], MARS [@friedman_multivariate_1991], random forests [@breiman_random_2001], and super learner [@van_der_laan_super_2007]. Additional arguments can be passed to the Step 1 estimation function via the `...` call to `tunevt`. For example, to specify the super learner library one can pass on the `SL.library` argument which is in turn passed to `SuperLearner`:

```{r echo = TRUE, eval = FALSE}
tunevt(
  data, step1 = "superlearner", SL.library = c("SL.randomForest", "SL.gam"),
  step2 = "rtree", alpha0 = 0.05, p_reps = 100
  )
```

See the help files for the relevant estimation functions for all additional arguments (e.g., `?SuperLearner::SuperLearner`).

| Method        | `step1` Argument | Estimation Function          |
|---------------|------------------|------------------------------|
| LASSO         | `"lasso"`        | `glmnet::cv.glmnet`          |
| MARS          | `"mars"`         | `earth::earth`               |
| Random Forest | `"randomforest"` | `randomForestSRC::rfsrc`     |
| Super Learner | `"superlearner"` | `SuperLearner::SuperLearner` |

: Supported Step 1 methods and estimation functions

## Virtual Twins Step 2

A simple and interpretable model, $\hat{g}(\boldsymbol{X};\theta)$ is fit to estimate $\operatorname{E}(\hat{Z}_i|\boldsymbol{X})$ or $\Pr(\hat{Z}_i>c|\boldsymbol{X})$ (i.e., the estimated individual treatment effects from Step 1, or the probability of the individual treatment effect exceeding a provided threshold) where $\theta$ is a penalty parameter specified to control model complexity.

Supported models include linear additive models tuned via the LASSO [@tibshirani_regression_1996], regression and classification trees [@breiman_classification_2017], and conditional inference trees [@hothorn_unbiased_2006].

The overarching estimation procedure selects the penalty parameter $\hat\theta_\alpha$ that results in a model fitting method with probability $\alpha$ of falsely fitting a non-constant Step 2 model when there is no treatment effect heterogeneity. See @wolf_permutation_2022 for full details of the penalty parameter selection algorithm.

| Method                     | Penalty Parameter | `step2` Argument | Estimation Function |
|----------------------------|-------------------|------------------|---------------------|
| LASSO                      | `lambda`          | `"lasso"`        | `glmnet::glmnet`    |
| Regression Tree            | `cp`              | `"rtree"`        | `rpart::rpart`      |
| Classification Tree        | `cp`              | `"classtree"`    | `rpart::rpart`      |
| Conditional Inference Tree | `mincriterion`    | `"ctree"`        | `party::ctree`      |

: Supported Step 2 methods, penalty parameters, and estimation functions

# Example: Modeling Treatment Response/Nonresponse

Data from a simulated clinical trial can be accessed with `data("tehtuner_example")`. There are 1000 observations with 8 continuous covariates (`V1` through `V8`) and 2 binary covariates (`V9` and `V10`). Treatment (`Trt`) was randomly assigned with a 1:1 allocation ratio. The primary outcome is `Y`.

```{r}
data("tehtuner_example")
```

Primary analyses found an average treatment effect of 1.65 (95% confidence interval: [0.78, 2.52]) but researchers have reason to suspect that a subgroup of subjects might not respond or may even respond negatively to the treatment. A secondary analyses seeks to identify subjects who are likely to have a negative response to treatment (i.e., have a CATE less than zero) for whom alternate interventions should be developed.

## Model Estimation

The first step to estimating the CATE through a tuned Virtual Twins model is to decide which estimation methods to use in Steps 1 and 2 (`step1` and `step2`). Without any further knowledge about how the covariates are related to the outcome, we will use a flexible model in Step 1 to ensure we can accurately estimate the response surfaces. Specifically, we will use a super learner model that uses a generalized additive model, linear model fit via the LASSO, and a random forest in its method library. Since we are interested in identifying subjects for whom the CATE is above or below a given threshold, we'll use a classification tree in Step 2 with a `threshold` of 0 to estimate $\Pr(\hat{Z}_i>0|\boldsymbol{X}_i)$.

After selecting estimation methods, we need to set the desired type-I error rate (`alpha0`). As this analysis is meant to be hypothesis generating, we selected larger error rate of 20% in order to increase the procedure's power and likelihood of discovering a subgroup of patients who aren't likely to respond to the treatment.

Lastly, we need to specify the number of permutations to perform (`p_reps`). More permutations allow us to better estimate the null distribution of the MNPP but require more computational time. We have found that 100 permutations is often sufficient unless the specified type-I error rate is extremely low.

```{r eval = FALSE}
vt_mod <- tunevt(
  data = tehtuner_example_big, Y = "Y", Trt = "Trt", 
  step1 = "superlearner", 
  SL.library = c("SL.gam", "SL.randomForest", "SL.glmnet"),
  step2 = "classtree",
  threshold = 0, 
  alpha0 = 0.2, 
  p_reps = 100, 
  keepz = TRUE
)
```

This model takes a while to fit as it requires fitting two super learner models `p_reps` times each. To speed that up we could run the code in parallel (in this case, across 10 cores):

```{r eval = FALSE}
cl <- parallel::makeCluster(10)
doParallel::registerDoParallel(cl)

vt_mod <- tunevt(
  data = tehtuner_example_big, Y = "Y", Trt = "Trt", 
  step1 = "superlearner", 
  SL.library = c("SL.gam", "SL.randomForest", "SL.glmnet"),
  step2 = "classtree",
  threshold = 0, 
  alpha0 = 0.2, 
  p_reps = 100, 
  keepz = TRUE, parallel = TRUE
)

parallel::stopCluster(cl)
```

```{r}
load("vt_superlearner.rda")
```

## Model Interpretation and Results

The estimated Virtual Twins model can be accessed via `$vtmod`. It is a classification tree with 2 terminal nodes. Subjects with $V_1 < -3.51$ are predicted to have a negative response to treatment (class = 0) with probability 0.32 while subjects with $V_1\ge-3.5$ are expected to benefit from treatment 96% of the time. Importantly, because of the frequentist properties of this method, we can conclude that the probability of treatment benefit is heterogeneous in the population at the 20% level.

```{r}
vt_mod$vtmod
```

Since a classification tree was used in Step 2, it will be an an object of class `rpart` and work with functions such as `rpart.plot`.

```{r warning=FALSE, fig.height=4}
rpart.plot::rpart.plot(vt_mod$vtmod)
```

Because `keepz` was set to `TRUE`, the estimated individual treatment effects from Step 1 can be accessed via `$z`. This allows us to look at the distribution of the estimated effects in both of the groups identified in the Step 2 model (those with $V_1<-3.5$ and those with $V_1\ge-3.5$).

```{r fig.height=5}
boxplot(
  vt_mod$z ~ tehtuner_example_big$V1 < -3.51,
  xlab = expression(V[1] < -3.51),
  ylab = "Individual Treatment Effect"
)
```

In order to select the penalty parameter the MNPP for each permuted dataset was recorded. These samples from the null distribution are located in `$theta_null`.

```{r}
hist(
  vt_mod$theta_null,
  xlab = expression(hat(theta)[N]),
  main = "Estimated Null Distribution of the MNPP"
  )
```

Using this information, we can calculate the probability of observing a MNPP as or more extreme than our data's MNPP when there is no effect heterogeneity. This quantity behaves similarly to a p-value; if it is less than $\alpha$, the model will detect effect heterogeneity.

```{r}
mean(vt_mod$theta_null >= vt_mod$mnpp)
```

# References
